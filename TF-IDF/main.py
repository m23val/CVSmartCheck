from fastapi import FastAPI, UploadFile, File, Request, Form
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import os
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import tempfile
from pathlib import Path
import re
from typing import List, Dict, Tuple, Set
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

app = FastAPI()

# Crear directorios si no existen
os.makedirs("static", exist_ok=True)
os.makedirs("templates", exist_ok=True)

app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# ===== MODELO EXPERIMENTAL DE AN√ÅLISIS SEM√ÅNTICO CORREGIDO =====
class TFIDFSemanticAnalyzer:
    """
    Implementaci√≥n experimental CORREGIDA de an√°lisis sem√°ntico para CVs
    utilizando TF-IDF y similitud coseno con evaluaci√≥n m√°s justa.
    """
    
    def __init__(self):
        """Inicializa el analizador con criterios m√°s realistas"""
        # Textos ideales SIMPLIFICADOS y m√°s accesibles
        self.textos_ideales = {
            "Desarrollador Full Stack": {
                "perfil": "desarrollador programador software web frontend backend aplicaciones tecnolog√≠a sistemas",
                "experiencia": "desarrollo programaci√≥n proyectos aplicaciones web software sistemas experiencia trabajo",
                "habilidades": "javascript html css react angular vue node python java php sql base datos git",
                "educacion": "ingenier√≠a sistemas inform√°tica programaci√≥n universidad instituto estudios tecnolog√≠a",
                "certificados": "certificaci√≥n curso capacitaci√≥n formaci√≥n desarrollo programaci√≥n tecnolog√≠a",
                "idiomas": "ingl√©s espa√±ol comunicaci√≥n t√©cnico internacional documentaci√≥n",
                "datos": "contacto email tel√©fono linkedin github portafolio informaci√≥n personal",
                "formato": "organizado estructurado claro profesional secciones informaci√≥n completa"
            },
            "Administrador de Bases de Datos (DBA)": {
                "perfil": "administrador base datos sql servidor gesti√≥n an√°lisis sistemas informaci√≥n",
                "experiencia": "administraci√≥n base datos sql servidor gesti√≥n an√°lisis proyectos sistemas",
                "habilidades": "sql mysql postgresql oracle mongodb base datos consultas servidor administraci√≥n",
                "educacion": "ingenier√≠a sistemas inform√°tica base datos universidad instituto estudios",
                "certificados": "certificaci√≥n sql base datos administraci√≥n oracle mysql postgresql",
                "idiomas": "ingl√©s espa√±ol t√©cnico comunicaci√≥n documentaci√≥n internacional",
                "datos": "contacto email tel√©fono linkedin informaci√≥n profesional",
                "formato": "estructurado organizado profesional secciones informaci√≥n t√©cnica"
            },
            "Ingeniero DevOps": {
                "perfil": "devops automatizaci√≥n infraestructura cloud contenedores deployment sistemas",
                "experiencia": "devops automatizaci√≥n infraestructura cloud deployment sistemas proyectos",
                "habilidades": "docker kubernetes aws azure terraform ansible jenkins git linux automatizaci√≥n",
                "educacion": "ingenier√≠a sistemas inform√°tica cloud devops universidad instituto",
                "certificados": "certificaci√≥n aws azure kubernetes docker devops cloud infraestructura",
                "idiomas": "ingl√©s espa√±ol t√©cnico internacional cloud documentaci√≥n",
                "datos": "contacto email linkedin github portafolio t√©cnico informaci√≥n",
                "formato": "t√©cnico estructurado m√©tricas proyectos infraestructura organizado"
            },
            "Cient√≠fico de Datos / ML Engineer": {
                "perfil": "datos an√°lisis estad√≠stica machine learning python ciencia investigaci√≥n",
                "experiencia": "an√°lisis datos estad√≠stica machine learning python proyectos investigaci√≥n",
                "habilidades": "python r sql pandas numpy machine learning estad√≠stica an√°lisis visualizaci√≥n tableau power bi excel",
                "educacion": "ingenier√≠a sistemas matem√°ticas estad√≠stica ciencia datos universidad",
                "certificados": "certificaci√≥n an√°lisis datos python machine learning estad√≠stica coursera",
                "idiomas": "ingl√©s espa√±ol cient√≠fico t√©cnico an√°lisis comunicaci√≥n",
                "datos": "contacto email linkedin github proyectos datos informaci√≥n",
                "formato": "anal√≠tico cuantificado m√©tricas proyectos datos organizado estructurado"
            },
            "Desarrollador de Aplicaciones M√≥viles": {
                "perfil": "m√≥vil mobile aplicaciones ios android desarrollo programaci√≥n apps",
                "experiencia": "desarrollo m√≥vil aplicaciones ios android mobile programaci√≥n proyectos",
                "habilidades": "swift kotlin java react native flutter ios android mobile desarrollo programaci√≥n",
                "educacion": "ingenier√≠a desarrollo software m√≥vil programaci√≥n universidad instituto",
                "certificados": "certificaci√≥n ios android mobile desarrollo swift kotlin programaci√≥n",
                "idiomas": "ingl√©s espa√±ol t√©cnico m√≥vil documentaci√≥n internacional",
                "datos": "contacto email portafolio apps github linkedin informaci√≥n",
                "formato": "m√≥vil apps desarrolladas proyectos portafolio organizado profesional"
            }
        }
        
        # Palabras clave EXPANDIDAS con mayor cobertura
        self.palabras_clave = {
            "Desarrollador Full Stack": [
                # Lenguajes de programaci√≥n
                "javascript", "js", "typescript", "python", "java", "php", "html", "css", "sql",
                # Frameworks y bibliotecas
                "react", "angular", "vue", "node", "express", "django", "flask", "laravel",
                # Conceptos generales
                "desarrollo", "programaci√≥n", "web", "frontend", "backend", "fullstack", "full stack",
                "api", "rest", "base de datos", "bases de datos", "git", "github", "software"
            ],
            "Administrador de Bases de Datos (DBA)": [
                # Sistemas de BD
                "sql", "mysql", "postgresql", "oracle", "mongodb", "redis", "sqlite",
                # Conceptos de BD
                "base de datos", "bases de datos", "bd", "database", "consultas", "queries",
                "administraci√≥n", "gesti√≥n", "servidor", "server", "backup", "recovery",
                # An√°lisis y optimizaci√≥n
                "an√°lisis", "optimizaci√≥n", "performance", "√≠ndices", "reporting", "datos", "data"
            ],
            "Ingeniero DevOps": [
                # Herramientas principales
                "docker", "kubernetes", "terraform", "ansible", "jenkins", "git",
                # Cloud providers
                "aws", "azure", "gcp", "google cloud", "cloud", "nube",
                # Conceptos DevOps
                "devops", "automatizaci√≥n", "ci/cd", "deployment", "infraestructura",
                "contenedores", "containers", "pipeline", "monitoreo", "linux", "scripting"
            ],
            "Cient√≠fico de Datos / ML Engineer": [
                # Lenguajes
                "python", "r", "sql", "scala",
                # Bibliotecas de datos
                "pandas", "numpy", "scipy", "matplotlib", "seaborn", "plotly",
                # Machine Learning
                "machine learning", "ml", "tensorflow", "pytorch", "scikit-learn", "keras",
                # Conceptos generales
                "an√°lisis", "datos", "data", "estad√≠stica", "statistics", "visualizaci√≥n",
                "ciencia de datos", "data science", "big data", "tableau", "power bi", "excel"
            ],
            "Desarrollador de Aplicaciones M√≥viles": [
                # Lenguajes m√≥viles
                "swift", "kotlin", "java", "dart", "objective-c",
                # Frameworks
                "react native", "flutter", "ionic", "xamarin",
                # Plataformas
                "ios", "android", "mobile", "m√≥vil", "app", "aplicaci√≥n",
                # Herramientas
                "xcode", "android studio", "firebase", "desarrollo m√≥vil", "programaci√≥n m√≥vil"
            ]
        }
        
        print("‚úÖ Analizador sem√°ntico TF-IDF CORREGIDO inicializado")
    
    def extraer_secciones_cv(self, texto_completo):
        """Extrae secciones del CV de manera m√°s inteligente y flexible"""
        secciones = {}
        texto_lower = texto_completo.lower()
        
        # Patrones de detecci√≥n M√ÅS SIMPLES y EFECTIVOS
        patrones_seccion = {
            "perfil": [
                r"(?:perfil|resumen|objetivo|presentaci√≥n|sobre m√≠|summary).*?(?=\n.*?(?:experiencia|habilidades|educaci√≥n|formaci√≥n)|\Z)",
                r"^(.{100,400}?)(?=\n.*?(?:experiencia|habilidades|educaci√≥n)|\Z)"  # Primeros p√°rrafos como perfil
            ],
            "habilidades": [
                r"(?:habilidades|competencias|skills|conocimientos|tecnolog√≠as|lenguajes).*?(?=\n.*?(?:experiencia|educaci√≥n|certificados|idiomas)|\Z)",
                r"(?:python|javascript|java|sql|html|css|react|angular).*?(?=\n.*?(?:experiencia|educaci√≥n)|\Z)"
            ],
            "experiencia": [
                r"(?:experiencia|laboral|profesional|trabajo|proyectos|pr√°ticas).*?(?=\n.*?(?:educaci√≥n|formaci√≥n|habilidades)|\Z)",
                r"(?:desarrollador|ingeniero|analista|programador|especialista).*?(?=\n.*?(?:educaci√≥n|habilidades)|\Z)"
            ],
            "educacion": [
                r"(?:educaci√≥n|formaci√≥n|estudios|universidad|instituto|grado|m√°ster|licenciatura).*?(?=\n.*?(?:experiencia|certificados|habilidades)|\Z)",
                r"(?:ingenier√≠a|carrera|bachillerato).*?(?=\n.*?(?:experiencia|certificados)|\Z)"
            ],
            "certificados": [
                r"(?:certificados|certificaciones|cursos|diplomas|capacitaci√≥n).*?(?=\n.*?(?:idiomas|referencias|habilidades)|\Z)",
                r"(?:coursera|udemy|edx|certificaci√≥n|curso).*?(?=\n.*?(?:idiomas|referencias)|\Z)"
            ],
            "idiomas": [
                r"(?:idiomas|lenguajes|languages).*?(?=\n.*?(?:referencias|contacto)|\Z)",
                r"(?:ingl√©s|espa√±ol|franc√©s|alem√°n|nativo|intermedio|avanzado|c1|b2).*?(?=\n.*?(?:referencias|contacto)|\Z)"
            ],
            "datos": [
                r"(?:contacto|informaci√≥n|datos|email|tel√©fono|linkedin|github).*?(?=\n.*?(?:perfil|resumen)|\Z)",
                r"(?:@|linkedin\.com|github\.com|\+\d+).*?(?=\n|\Z)"
            ]
        }
        
        # Extraer cada secci√≥n usando m√∫ltiples patrones
        for seccion, patrones in patrones_seccion.items():
            contenido_encontrado = ""
            
            for patron in patrones:
                matches = re.findall(patron, texto_completo, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match[0] else match[1] if len(match) > 1 else ""
                    if match and len(match.strip()) > 20:
                        contenido_encontrado += match.strip() + "\n"
            
            # Si encontramos contenido espec√≠fico, usarlo; sino, usar texto completo
            if contenido_encontrado.strip():
                secciones[seccion] = contenido_encontrado.strip()
                print(f"  ‚úÖ {seccion}: {len(secciones[seccion])} chars (espec√≠fico)")
            else:
                secciones[seccion] = texto_completo
                print(f"  üìÑ {seccion}: {len(secciones[seccion])} chars (general)")
        
        # Formato siempre usa texto completo
        secciones["formato"] = texto_completo
        
        return secciones
    
    def calcular_similitud_tfidf(self, texto1, texto2):
        """Calcula similitud TF-IDF con par√°metros M√ÅS GENEROSOS"""
        try:
            if not texto1 or not texto2:
                return 0.4  # Base m√°s alta
                
            t1 = str(texto1).lower().strip()
            t2 = str(texto2).lower().strip()
            
            if len(t1) < 10 or len(t2) < 10:
                return 0.4  # Textos muy cortos
                
            if t1 == t2:
                return 0.8  # Textos id√©nticos
                
            try:
                # Vectorizer M√ÅS PERMISIVO
                vectorizer = TfidfVectorizer(
                    analyzer='word',
                    ngram_range=(1, 2),  # Solo 1-2 gramas
                    stop_words=['de', 'la', 'el', 'en', 'y', 'a', 'con', 'para', 'por'],
                    max_features=500,    # Menos features para mayor generalizaci√≥n
                    min_df=1,           # Aceptar palabras que aparecen solo una vez
                    lowercase=True,
                    token_pattern=r'\b\w+\b'  # Patr√≥n m√°s simple
                )
                
                tfidf_matrix = vectorizer.fit_transform([t1, t2])
                similitud = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
                
                # TRANSFORMACI√ìN PARA PUNTUACIONES M√ÅS ALTAS
                # Aplicar funci√≥n sigmoidea desplazada para aumentar puntuaciones
                similitud_ajustada = 0.3 + (similitud * 0.6)  # M√≠nimo 30%, m√°ximo 90%
                
                return max(0.3, min(0.9, float(similitud_ajustada)))
                
            except Exception as e:
                print(f"    ‚ö†Ô∏è Error TF-IDF interno: {e}")
                return 0.5
                
        except Exception as e:
            print(f"    ‚ö†Ô∏è Error TF-IDF: {e}")
            return 0.5
    
    def calcular_similitud_keywords(self, texto_seccion, puesto_clave):
        """Calcula similitud por palabras clave con M√ÅXIMA FLEXIBILIDAD y reconocimiento de habilidades transferibles"""
        try:
            if not texto_seccion or puesto_clave not in self.palabras_clave:
                return 0.4  # Base m√°s alta
            
            texto_lower = str(texto_seccion).lower()
            keywords_for_puesto = self.palabras_clave[puesto_clave]
            
            if not keywords_for_puesto:
                return 0.4
            
            # B√öSQUEDA S√öPER FLEXIBLE de keywords
            encontradas = 0
            palabras_encontradas = []
            puntos_bonus = 0
            
            for keyword in keywords_for_puesto:
                # B√∫squeda exacta
                if keyword.lower() in texto_lower:
                    encontradas += 1
                    palabras_encontradas.append(keyword)
                # B√∫squeda de variaciones comunes
                elif self._buscar_variaciones(keyword, texto_lower):
                    encontradas += 1
                    palabras_encontradas.append(f"{keyword}*")
            
            # RECONOCIMIENTO DE HABILIDADES TRANSFERIBLES
            # Si es Full Stack, reconocer habilidades de programaci√≥n general
            if puesto_clave == "Desarrollador Full Stack":
                habilidades_transferibles = [
                    "python", "programaci√≥n", "desarrollo", "sql", "base de datos", "bases de datos",
                    "mongodb", "postgresql", "mysql", "git", "github", "an√°lisis", "algoritmos",
                    "pandas", "numpy", "api", "web", "dashboard", "visualizaci√≥n", "estad√≠stica"
                ]
                
                for habilidad in habilidades_transferibles:
                    if habilidad in texto_lower and habilidad not in [k.lower() for k in palabras_encontradas]:
                        puntos_bonus += 1
                        palabras_encontradas.append(f"üí°{habilidad}")
            
            # Si es Data Science, reconocer m√°s habilidades espec√≠ficas
            elif "Datos" in puesto_clave or "ML" in puesto_clave:
                habilidades_transferibles = [
                    "an√°lisis", "estad√≠stica", "visualizaci√≥n", "dashboard", "reporting",
                    "predicci√≥n", "modelos", "algoritmos", "clustering", "regresi√≥n", "clasificaci√≥n"
                ]
                
                for habilidad in habilidades_transferibles:
                    if habilidad in texto_lower and habilidad not in [k.lower() for k in palabras_encontradas]:
                        puntos_bonus += 1
                        palabras_encontradas.append(f"üí°{habilidad}")
            
            encontradas_total = encontradas + puntos_bonus
            
            if encontradas_total > 0:
                print(f"    üéØ Keywords: {encontradas}/{len(keywords_for_puesto)} directas + {puntos_bonus} transferibles")
                print(f"    üìã Encontradas: {', '.join(palabras_encontradas[:10])}")
            
            # C√ÅLCULO S√öPER GENEROSO con habilidades transferibles
            proporcion_base = encontradas / len(keywords_for_puesto)
            bonus_transferible = min(0.4, puntos_bonus * 0.05)  # Max 40% bonus
            
            similitud_total = proporcion_base + bonus_transferible
            
            # BOOST seg√∫n cantidad total de keywords encontradas
            if encontradas_total >= 8:
                similitud = min(0.95, similitud_total + 0.25)  # Boost enorme
            elif encontradas_total >= 5:
                similitud = min(0.85, similitud_total + 0.2)   # Gran boost
            elif encontradas_total >= 3:
                similitud = min(0.75, similitud_total + 0.15)  # Boost medio
            elif encontradas_total >= 1:
                similitud = min(0.65, similitud_total + 0.1)   # Boost peque√±o
            else:
                similitud = 0.2  # M√≠nimo m√°s alto
            
            return round(similitud, 3)
            
        except Exception as e:
            print(f"    ‚ö†Ô∏è Error keywords: {e}")
            return 0.5
    
    def _buscar_variaciones(self, keyword, texto):
        """Busca variaciones comunes de las palabras clave con MAYOR COBERTURA"""
        variaciones = {
            "javascript": ["js", "ecmascript", "node", "nodejs", "react", "angular", "vue"],
            "bases de datos": ["bd", "database", "sql", "mysql", "postgresql", "mongodb", "redis"],
            "base de datos": ["bd", "database", "sql", "mysql", "postgresql", "mongodb", "redis"],
            "machine learning": ["ml", "aprendizaje autom√°tico", "ia", "inteligencia artificial"],
            "desarrollo": ["development", "dev", "programaci√≥n", "coding", "software"],
            "programaci√≥n": ["programming", "desarrollo", "dev", "coding", "software"],
            "an√°lisis": ["analysis", "anal√≠tica", "analytics", "data analysis"],
            "react": ["reactjs", "react.js", "frontend"],
            "angular": ["angularjs", "frontend"],
            "full stack": ["fullstack", "full-stack"],
            "python": ["py", "pandas", "numpy", "django", "flask"],
            "sql": ["mysql", "postgresql", "sqlite", "oracle", "base de datos"],
            "web": ["frontend", "backend", "javascript", "html", "css"],
            "frontend": ["front-end", "react", "angular", "vue", "javascript"],
            "backend": ["back-end", "servidor", "api", "node", "python"],
            "git": ["github", "gitlab", "control de versiones", "versionado"],
            "api": ["rest", "restful", "endpoint", "web service"],
            "html": ["markup", "web", "frontend"],
            "css": ["styles", "styling", "frontend", "web"]
        }
        
        if keyword in variaciones:
            encontradas = [var for var in variaciones[keyword] if var in texto]
            if encontradas:
                return True
        
        # B√∫squeda adicional de t√©rminos relacionados
        terminos_relacionados = {
            "desarrollo": ["proyecto", "implement√©", "desarroll√©", "cre√©", "constru√≠"],
            "programaci√≥n": ["c√≥digo", "script", "algoritmo", "funci√≥n", "m√©todo"],
            "an√°lisis": ["analizar", "analizando", "estudi√≥", "investig√≥", "examin√≥"],
            "experiencia": ["trabaj√©", "colabor√©", "particip√©", "realic√©", "ejecut√©"]
        }
        
        if keyword in terminos_relacionados:
            return any(termino in texto for termino in terminos_relacionados[keyword])
        
        return False
    
    def analizar_cv(self, texto_cv, puesto):
        """An√°lisis completo del CV con criterios CORREGIDOS Y JUSTOS"""
        resultados = {}
        
        print(f"\nüîÑ AN√ÅLISIS EXPERIMENTAL CORREGIDO")
        print(f"üìã Puesto: {puesto}")
        print(f"üìÑ CV: {len(texto_cv)} caracteres")
        
        # Buscar puesto con MAYOR FLEXIBILIDAD
        puesto_clave = self._encontrar_puesto_clave(puesto)
        print(f"üéØ Usando perfil: '{puesto_clave}'")
        
        textos_ideales = self.textos_ideales[puesto_clave]
        
        # Extraer secciones
        secciones_cv = self.extraer_secciones_cv(texto_cv)
        
        # Analizar cada secci√≥n con criterios MEJORADOS
        for seccion, texto_ideal in textos_ideales.items():
            texto_seccion = secciones_cv.get(seccion, texto_cv)
            
            print(f"\n  üìä Analizando {seccion.upper()}:")
            
            # Calcular m√©tricas
            sim_tfidf = self.calcular_similitud_tfidf(texto_seccion, texto_ideal)
            sim_keywords = self.calcular_similitud_keywords(texto_seccion, puesto_clave)
            
            # Combinar m√©tricas con PESOS M√ÅS FAVORABLES A KEYWORDS
            sim_combinada = (sim_tfidf * 0.3) + (sim_keywords * 0.7)  # 70% peso a keywords
            
            # Criterios de nivel MUCHO M√ÅS JUSTOS
            if sim_combinada >= 0.6:
                nivel = "Alto"
                ajuste = 4
            elif sim_combinada >= 0.4:
                nivel = "Medio"
                ajuste = 2
            elif sim_combinada >= 0.2:
                nivel = "Bajo"
                ajuste = 1
            else:
                nivel = "Bajo"
                ajuste = 0
            
            resultados[seccion] = {
                "similitud_tfidf": round(sim_tfidf, 3),
                "similitud_keywords": round(sim_keywords, 3),
                "similitud_combinada": round(sim_combinada, 3),
                "nivel": nivel,
                "ajuste_puntos": ajuste
            }
            
            print(f"    ‚úÖ TF-IDF: {sim_tfidf:.1%} | Keywords: {sim_keywords:.1%} | Combined: {sim_combinada:.1%} ‚Üí {nivel}")
        
        return resultados
    
    def _encontrar_puesto_clave(self, puesto):
        """Encuentra el puesto clave con mayor flexibilidad"""
        # Mapeo de t√©rminos comunes
        mapeo_puestos = {
            "full stack": "Desarrollador Full Stack",
            "fullstack": "Desarrollador Full Stack",
            "frontend": "Desarrollador Full Stack",
            "backend": "Desarrollador Full Stack",
            "web": "Desarrollador Full Stack",
            "dba": "Administrador de Bases de Datos (DBA)",
            "base de datos": "Administrador de Bases de Datos (DBA)",
            "bases de datos": "Administrador de Bases de Datos (DBA)",
            "devops": "Ingeniero DevOps",
            "datos": "Cient√≠fico de Datos / ML Engineer",
            "data": "Cient√≠fico de Datos / ML Engineer",
            "machine learning": "Cient√≠fico de Datos / ML Engineer",
            "ml": "Cient√≠fico de Datos / ML Engineer",
            "m√≥vil": "Desarrollador de Aplicaciones M√≥viles",
            "mobile": "Desarrollador de Aplicaciones M√≥viles",
            "ios": "Desarrollador de Aplicaciones M√≥viles",
            "android": "Desarrollador de Aplicaciones M√≥viles"
        }
        
        puesto_lower = puesto.lower()
        
        # Buscar match directo
        if puesto in self.textos_ideales:
            return puesto
        
        # Buscar por mapeo
        for termino, puesto_mapeado in mapeo_puestos.items():
            if termino in puesto_lower:
                return puesto_mapeado
        
        # Buscar coincidencias parciales
        for puesto_existente in self.textos_ideales.keys():
            palabras_existente = puesto_existente.lower().split()
            palabras_busqueda = puesto_lower.split()
            
            if any(palabra in puesto_lower for palabra in palabras_existente) or \
               any(palabra in puesto_existente.lower() for palabra in palabras_busqueda):
                return puesto_existente
        
        # Default
        return "Desarrollador Full Stack"

# Inicializar analizador
semantic_analyzer = TFIDFSemanticAnalyzer()

# === Funciones de procesamiento de archivos ===
def extraer_texto_pdf(ruta: str) -> str:
    """Extrae texto de PDF"""
    try:
        import pypdf
        with open(ruta, 'rb') as file:
            reader = pypdf.PdfReader(file)
            texto = ""
            for page in reader.pages:
                if page.extract_text():
                    texto += page.extract_text() + "\n"
            return texto.strip()
    except ImportError:
        try:
            import PyPDF2
            with open(ruta, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                texto = ""
                for page in reader.pages:
                    if page.extract_text():
                        texto += page.extract_text() + "\n"
                return texto.strip()
        except ImportError:
            return "Error: Instala pypdf con 'pip install pypdf'"
    except Exception as e:
        return f"Error procesando PDF: {str(e)}"

def extraer_texto_docx(ruta: str) -> str:
    """Extrae texto de DOCX"""
    try:
        from docx import Document
        doc = Document(ruta)
        texto = ""
        for para in doc.paragraphs:
            if para.text.strip():
                texto += para.text + "\n"
        return texto.strip()
    except ImportError:
        return "Error: Instala python-docx con 'pip install python-docx'"
    except Exception as e:
        return f"Error procesando DOCX: {str(e)}"

async def procesar_archivo(archivo: UploadFile) -> str:
    """Procesa archivo subido"""
    try:
        print(f"üîÑ Procesando: {archivo.filename}")
        
        temp_dir = Path(tempfile.mkdtemp())
        temp_file = temp_dir / archivo.filename
        
        content = await archivo.read()
        if not content:
            return "Archivo vac√≠o"
        
        with open(temp_file, "wb") as f:
            f.write(content)
        
        if archivo.filename.lower().endswith('.pdf'):
            texto = extraer_texto_pdf(str(temp_file))
        elif archivo.filename.lower().endswith('.docx'):
            texto = extraer_texto_docx(str(temp_file))
        else:
            texto = "Formato no soportado"
        
        # Limpiar archivos temporales
        try:
            temp_file.unlink()
            temp_dir.rmdir()
        except:
            pass
        
        print(f"‚úÖ Extra√≠do: {len(texto)} caracteres")
        return texto
        
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return f"Error: {str(e)}"

# === Rutas de la aplicaci√≥n ===
@app.get("/", response_class=HTMLResponse)
async def mostrar_formulario(request: Request):
    return templates.TemplateResponse("index.html", {
        "request": request,
        "resultado": None,
        "error": None,
        "detalles": [],
        "recomendaciones": [],
        "contenido_cv": "",
        "nombre": "",
        "puesto": ""
    })

@app.post("/analizar", response_class=HTMLResponse)
async def analizar_cv_experimental(request: Request, archivo: UploadFile = File(...), puesto: str = Form(...)):
    try:
        print(f"\nüöÄ INICIANDO AN√ÅLISIS CORREGIDO")
        print(f"üìã Puesto: {puesto}")
        print(f"üìÑ Archivo: {archivo.filename}")
        
        # Validaciones
        if not puesto or puesto.startswith("--"):
            raise ValueError("Selecciona un puesto v√°lido")
        
        if not archivo.filename.lower().endswith((".pdf", ".docx")):
            raise ValueError("Solo PDF o DOCX")
        
        # Procesar archivo
        texto = await procesar_archivo(archivo)
        if len(texto.strip()) < 50:
            raise ValueError("Texto insuficiente en el archivo")
        
        # An√°lisis sem√°ntico
        print("\nüß† INICIANDO AN√ÅLISIS SEM√ÅNTICO CORREGIDO...")
        metricas = semantic_analyzer.analizar_cv(texto, puesto)
        
        # Convertir para UI con PUNTUACI√ìN CORREGIDA
        resultados_ui = []
        for seccion, datos in metricas.items():
            puntuacion_base = 10
            factor = datos["similitud_combinada"]
            
            # ESCALA DE PUNTUACI√ìN MUCHO M√ÅS GENEROSA
            if factor >= 0.6:       # Alto
                puntuacion = min(10, 9 + round(factor))      # 9-10 puntos
            elif factor >= 0.4:     # Medio
                puntuacion = min(9, 7 + round(factor * 2))   # 7-9 puntos  
            elif factor >= 0.2:     # Bajo
                puntuacion = min(7, 5 + round(factor * 3))   # 5-7 puntos
            else:                   # Muy bajo
                puntuacion = max(3, round(factor * 10))      # 3-5 puntos
            
            nivel = datos["nivel"]
            if nivel == "Alto":
                mensaje = "‚úÖ Excelente coherencia sem√°ntica"
            elif nivel == "Medio":
                mensaje = "‚ö†Ô∏è Coherencia aceptable"
            else:
                mensaje = "‚ùå Coherencia b√°sica"
            
            mensaje += f" [TF-IDF: {int(datos['similitud_tfidf']*100)}%]"
            
            resultados_ui.append((
                seccion.capitalize(),
                puntuacion,
                puntuacion_base,
                mensaje
            ))
        
        # Puntuaci√≥n total
        puntaje_total = sum(p for _, p, _, _ in resultados_ui)
        
        # Recomendaciones mejoradas
        recomendaciones = []
        secciones_bajas = sorted(metricas.items(), key=lambda x: x[1]["similitud_combinada"])[:2]
        
        for seccion, datos in secciones_bajas:
            if datos["similitud_combinada"] < 0.5:
                if seccion == "habilidades":
                    recomendaciones.append(f"Ampl√≠a tu secci√≥n de habilidades t√©cnicas para {puesto}. Incluye m√°s tecnolog√≠as espec√≠ficas del √°rea.")
                elif seccion == "experiencia":
                    recomendaciones.append(f"Destaca proyectos y logros m√°s relacionados con {puesto}. Cuantifica tus resultados.")
                elif seccion == "perfil":
                    recomendaciones.append(f"Personaliza tu perfil profesional para {puesto}, destacando competencias clave del √°rea.")
        
        if len(recomendaciones) < 2:
            recomendaciones.append(f"Tu CV muestra buena compatibilidad con {puesto}. Contin√∫a desarrollando proyectos en esta √°rea.")
        
        # M√©tricas para visualizaci√≥n
        metricas_ui = []
        for seccion, datos in metricas.items():
            metricas_ui.append({
                "seccion": seccion.capitalize(),
                "similitud": round(datos["similitud_combinada"] * 100),
                "nivel": datos["nivel"],
                "ajuste": datos["ajuste_puntos"]
            })
        
        print(f"\nüéØ AN√ÅLISIS COMPLETADO")
        print(f"üìä Puntuaci√≥n total: {puntaje_total}/80")
        print(f"üìà Promedio: {puntaje_total/8:.1f}/10")
        
        return templates.TemplateResponse("index.html", {
            "request": request,
            "resultado": puntaje_total,
            "detalles": resultados_ui,
            "nombre": archivo.filename,
            "contenido_cv": texto[:15000] + ("..." if len(texto) > 15000 else ""),
            "recomendaciones": recomendaciones,
            "puesto": puesto,
            "metricas_semanticas": metricas_ui,
            "modo_experimental": True
        })
        
    except Exception as e:
        print(f"‚ùå ERROR: {str(e)}")
        return templates.TemplateResponse("index.html", {
            "request": request,
            "error": f"Error: {str(e)}",
            "resultado": None,
            "detalles": [],
            "recomendaciones": [],
            "contenido_cv": "",
            "nombre": "",
            "puesto": ""
        })

@app.middleware("http")
async def add_headers(request: Request, call_next):
    print(f"üåê {request.method} {request.url}")
    response = await call_next(request)
    response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
    response.headers["Pragma"] = "no-cache" 
    response.headers["Expires"] = "0"
    return response